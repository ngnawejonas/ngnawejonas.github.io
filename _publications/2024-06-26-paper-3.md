---
title: "Detecting Brittle Decisions for Free: Leveraging Margin Consistency in Deep Robust Classifiers."
collection: publications
category: conferences
permalink: /publication/2010-10-01-paper-title-number-2
excerpt: 'A novel property of deep robust classifiers that allows to use the logit margin as a proxy score for input margin and efficiently detect non-robust samples, vulnerable to adversarial attacks.'
date: 2024-06-26
venue: 'Neurips 2024'
slidesurl: 'http://ngnawejonas.github.io/files/Margin_Consistency_slides.pdf'
paperurl: 'https://arxiv.org/abs/2406.18451'
citation: 'Ngnawé, J., Sahoo, S., Pequignot, Y., Precioso, F., & Gagné, C. (2024). Detecting Brittle Decisions for Free: Leveraging Margin Consistency in Deep Robust Classifiers. arXiv preprint arXiv:2406.18451.'
---

Despite extensive research on adversarial training strategies to improve robustness, the decisions of even the most robust deep learning models can still be quite sensitive to imperceptible perturbations, creating serious risks when deploying them for high-stakes real-world applications. While detecting such cases may be critical, evaluating a model's vulnerability at a per-instance level using adversarial attacks is computationally too intensive and unsuitable for real-time deployment scenarios. The input space margin is the exact score to detect non-robust samples and is intractable for deep neural networks. This paper introduces the concept of margin consistency -- a property that links the input space margins and the logit margins in robust models -- for efficient detection of vulnerable samples. First, we establish that margin consistency is a necessary and sufficient condition to use a model's logit margin as a score for identifying non-robust samples. Next, through comprehensive empirical analysis of various robustly trained models on CIFAR10 and CIFAR100 datasets, we show that they indicate strong margin consistency with a strong correlation between their input space margins and the logit margins. Then, we show that we can effectively use the logit margin to confidently detect brittle decisions with such models and accurately estimate robust accuracy on an arbitrarily large test set by estimating the input margins only on a small subset. Finally, we address cases where the model is not sufficiently margin-consistent by learning a pseudo-margin from the feature representation. Our findings highlight the potential of leveraging deep representations to efficiently assess adversarial vulnerability in deployment scenarios.